{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Calculate the Inception Score (IS) and Frechet Inception Distance (FID) between real images and themselves as a reference.",
   "id": "d6938488a0c3d594"
  },
  {
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-30T09:35:20.132975Z",
     "iopub.status.busy": "2024-11-30T09:35:20.132437Z",
     "iopub.status.idle": "2024-11-30T09:35:40.521211Z",
     "shell.execute_reply": "2024-11-30T09:35:40.519992Z",
     "shell.execute_reply.started": "2024-11-30T09:35:20.132939Z"
    },
    "tags": []
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inception Score: 2.6062247520215522\n",
      "Frechet Inception Distance: 4.373965035617817e-11\n"
     ]
    }
   ],
   "execution_count": 3,
   "source": [
    "import torch\n",
    "from torchvision import models, transforms\n",
    "from torchvision.models import Inception_V3_Weights\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Inception v3 \n",
    "inception = models.inception_v3(weights=Inception_V3_Weights.IMAGENET1K_V1)\n",
    "inception = inception.to(device).eval()\n",
    "inception.fc = torch.nn.Sequential(inception.fc, torch.nn.Softmax(dim=1))\n",
    "\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize((299, 299)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "def load_images_from_folder(folder, preprocess):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img_path = os.path.join(folder, filename)\n",
    "        with Image.open(img_path) as img:\n",
    "            img = preprocess(img)\n",
    "            images.append(img)\n",
    "    return torch.stack(images)\n",
    "\n",
    "def get_activations(images, model, batch_size=64):\n",
    "    model.eval()\n",
    "    n_batches = len(images) // batch_size\n",
    "    n_used_imgs = n_batches * batch_size\n",
    "    pred_arr = np.empty((n_used_imgs, 1000))\n",
    "    \n",
    "    for i in range(n_batches):\n",
    "        start = i * batch_size\n",
    "        end = start + batch_size\n",
    "        batch = images[start:end]\n",
    "        batch = batch.to(device)\n",
    "        with torch.no_grad():\n",
    "            pred = model(batch) \n",
    "        pred_arr[start:end] = pred.cpu().data.numpy()\n",
    "    return pred_arr\n",
    "\n",
    "def calculate_inception_score(p_yx, eps=1E-16):\n",
    "    p_y = np.expand_dims(np.mean(p_yx, 0), 0)  \n",
    "    kl_d = p_yx * (np.log(p_yx + eps) - np.log(p_y + eps))  \n",
    "    sum_kl_d = np.sum(kl_d, 1) \n",
    "    avg_kl_d = np.mean(sum_kl_d)  \n",
    "    is_score = np.exp(avg_kl_d)  \n",
    "    return is_score\n",
    "\n",
    "def calculate_fid(mu1, sigma1, mu2, sigma2):\n",
    "    ssdiff = np.sum((mu1 - mu2)**2.0)\n",
    "    covmean = sqrtm(sigma1.dot(sigma2))\n",
    "    if np.iscomplexobj(covmean):\n",
    "        covmean = covmean.real\n",
    "    fid = ssdiff + np.trace(sigma1 + sigma2 - 2.0 * covmean)\n",
    "    return fid\n",
    "\n",
    "real_images = load_images_from_folder('Cloud', preprocess)\n",
    "generated_images = load_images_from_folder('Cloud', preprocess)\n",
    "\n",
    "real_probs = get_activations(real_images, inception)\n",
    "generated_probs = get_activations(generated_images, inception)\n",
    "\n",
    "# Inception Score\n",
    "is_score = calculate_inception_score(generated_probs)\n",
    "print(f'Inception Score: {is_score}')\n",
    "\n",
    "# Frechet Inception Distance\n",
    "mu_real, sigma_real = real_probs.mean(axis=0), np.cov(real_probs, rowvar=False)\n",
    "mu_generated, sigma_generated = generated_probs.mean(axis=0), np.cov(generated_probs, rowvar=False)\n",
    "fid = calculate_fid(mu_real, sigma_real, mu_generated, sigma_generated)\n",
    "print(f'Frechet Inception Distance: {fid}')"
   ],
   "id": "ec7d93ae-2622-4d71-b047-82dd16384eb7"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4765dfd0-e2e7-445c-ad22-77fcd7531fa3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-30T09:34:05.418531Z",
     "iopub.status.busy": "2024-11-30T09:34:05.417640Z",
     "iopub.status.idle": "2024-11-30T09:34:19.003990Z",
     "shell.execute_reply": "2024-11-30T09:34:19.002529Z",
     "shell.execute_reply.started": "2024-11-30T09:34:05.418464Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inception Score: 1.8212098539603365\n",
      "Frechet Inception Distance: 0.09150639215606834\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision import models, transforms\n",
    "from torchvision.models import Inception_V3_Weights\n",
    "from scipy.linalg import sqrtm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Inception v3 \n",
    "inception = models.inception_v3(weights=Inception_V3_Weights.IMAGENET1K_V1)\n",
    "inception = inception.to(device).eval()\n",
    "inception.fc = torch.nn.Sequential(inception.fc, torch.nn.Softmax(dim=1))\n",
    "\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize((299, 299)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "def load_images_from_folder(folder, preprocess):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img_path = os.path.join(folder, filename)\n",
    "        with Image.open(img_path) as img:\n",
    "            img = preprocess(img)\n",
    "            images.append(img)\n",
    "    return torch.stack(images)\n",
    "\n",
    "def get_activations(images, model, batch_size=64):\n",
    "    model.eval()\n",
    "    n_batches = len(images) // batch_size\n",
    "    n_used_imgs = n_batches * batch_size\n",
    "    pred_arr = np.empty((n_used_imgs, 1000))\n",
    "    \n",
    "    for i in range(n_batches):\n",
    "        start = i * batch_size\n",
    "        end = start + batch_size\n",
    "        batch = images[start:end]\n",
    "        batch = batch.to(device)\n",
    "        with torch.no_grad():\n",
    "            pred = model(batch)    \n",
    "        pred_arr[start:end] = pred.cpu().data.numpy()\n",
    "    return pred_arr\n",
    "\n",
    "def calculate_inception_score(p_yx, eps=1E-16):\n",
    "    p_y = np.expand_dims(np.mean(p_yx, 0), 0)  \n",
    "    kl_d = p_yx * (np.log(p_yx + eps) - np.log(p_y + eps))  \n",
    "    sum_kl_d = np.sum(kl_d, 1)  \n",
    "    avg_kl_d = np.mean(sum_kl_d)  \n",
    "    is_score = np.exp(avg_kl_d) \n",
    "    return is_score\n",
    "\n",
    "def calculate_fid(mu1, sigma1, mu2, sigma2):\n",
    "    ssdiff = np.sum((mu1 - mu2)**2.0)\n",
    "    covmean = sqrtm(sigma1.dot(sigma2))\n",
    "    if np.iscomplexobj(covmean):\n",
    "        covmean = covmean.real\n",
    "    fid = ssdiff + np.trace(sigma1 + sigma2 - 2.0 * covmean)\n",
    "    return fid\n",
    "\n",
    "real_images = load_images_from_folder('Cloud', preprocess)\n",
    "generated_images = load_images_from_folder('result', preprocess)\n",
    "\n",
    "real_probs = get_activations(real_images, inception)\n",
    "generated_probs = get_activations(generated_images, inception)\n",
    "\n",
    "# Inception Score\n",
    "is_score = calculate_inception_score(generated_probs)\n",
    "print(f'Inception Score: {is_score}')\n",
    "\n",
    "# Frechet Inception Distance:\n",
    "mu_real, sigma_real = real_probs.mean(axis=0), np.cov(real_probs, rowvar=False)\n",
    "mu_generated, sigma_generated = generated_probs.mean(axis=0), np.cov(generated_probs, rowvar=False)\n",
    "fid = calculate_fid(mu_real, sigma_real, mu_generated, sigma_generated)\n",
    "print(f'Frechet Inception Distance: {fid}')"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "From the FID perspective, the generation quality is quite good, and indeed, the generated images do appear more realistic compared to those produced by GAN models. The IS value is a bit low, but considering that both training and generation are focused on a single category of clouds, a lower IS value is also expected.",
   "id": "9baf79064709c9f0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
