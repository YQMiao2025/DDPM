{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ecf2fec-78df-46ad-9ae4-818439863f02",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-30T04:55:19.633809Z",
     "iopub.status.busy": "2024-11-30T04:55:19.632887Z",
     "iopub.status.idle": "2024-11-30T06:11:28.582751Z",
     "shell.execute_reply": "2024-11-30T06:11:28.581624Z",
     "shell.execute_reply.started": "2024-11-30T04:55:19.633740Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 0.4304, Time: 19.4753s\n",
      "Epoch [2/100], Loss: 0.3557, Time: 38.5720s\n",
      "Epoch [3/100], Loss: 0.0601, Time: 57.6735s\n",
      "Epoch [4/100], Loss: 0.0606, Time: 76.7273s\n",
      "Epoch [5/100], Loss: 0.0411, Time: 95.8073s\n",
      "Epoch [6/100], Loss: 0.0308, Time: 114.8980s\n",
      "Epoch [7/100], Loss: 0.0427, Time: 134.0023s\n",
      "Epoch [8/100], Loss: 0.0268, Time: 153.1045s\n",
      "Epoch [9/100], Loss: 0.0523, Time: 172.2829s\n",
      "Epoch [10/100], Loss: 0.0226, Time: 191.4206s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sampling loop time step: 100%|██████████| 1000/1000 [00:43<00:00, 23.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Got 9/9 fake images.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/100], Loss: 0.1452, Time: 254.0299s\n",
      "Epoch [12/100], Loss: 0.0173, Time: 273.1156s\n",
      "Epoch [13/100], Loss: 0.0248, Time: 292.2285s\n",
      "Epoch [14/100], Loss: 0.0897, Time: 311.2967s\n",
      "Epoch [15/100], Loss: 0.0186, Time: 330.4343s\n",
      "Epoch [16/100], Loss: 0.2454, Time: 349.4972s\n",
      "Epoch [17/100], Loss: 0.0141, Time: 368.5627s\n",
      "Epoch [18/100], Loss: 0.0455, Time: 387.6396s\n",
      "Epoch [19/100], Loss: 0.0263, Time: 406.7111s\n",
      "Epoch [20/100], Loss: 0.0206, Time: 425.7963s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sampling loop time step: 100%|██████████| 1000/1000 [00:43<00:00, 23.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Got 9/9 fake images.\n",
      "Epoch [21/100], Loss: 0.0233, Time: 488.5989s\n",
      "Epoch [22/100], Loss: 0.1440, Time: 507.6994s\n",
      "Epoch [23/100], Loss: 0.0420, Time: 526.7880s\n",
      "Epoch [24/100], Loss: 0.0263, Time: 545.8663s\n",
      "Epoch [25/100], Loss: 0.0915, Time: 564.9412s\n",
      "Epoch [26/100], Loss: 0.0151, Time: 584.0369s\n",
      "Epoch [27/100], Loss: 0.0314, Time: 603.1167s\n",
      "Epoch [28/100], Loss: 0.0387, Time: 622.1889s\n",
      "Epoch [29/100], Loss: 0.0286, Time: 641.2782s\n",
      "Epoch [30/100], Loss: 0.0938, Time: 660.3648s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sampling loop time step: 100%|██████████| 1000/1000 [00:43<00:00, 23.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Got 9/9 fake images.\n",
      "Epoch [31/100], Loss: 0.1155, Time: 722.9131s\n",
      "Epoch [32/100], Loss: 0.0257, Time: 741.9967s\n",
      "Epoch [33/100], Loss: 0.0488, Time: 761.0916s\n",
      "Epoch [34/100], Loss: 0.0125, Time: 780.2044s\n",
      "Epoch [35/100], Loss: 0.1350, Time: 799.2690s\n",
      "Epoch [36/100], Loss: 0.0306, Time: 818.3507s\n",
      "Epoch [37/100], Loss: 0.0208, Time: 837.4302s\n",
      "Epoch [38/100], Loss: 0.0717, Time: 856.4821s\n",
      "Epoch [39/100], Loss: 0.1085, Time: 875.5561s\n",
      "Epoch [40/100], Loss: 0.0089, Time: 894.6443s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sampling loop time step: 100%|██████████| 1000/1000 [00:43<00:00, 23.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Got 9/9 fake images.\n",
      "Epoch [41/100], Loss: 0.0367, Time: 957.3359s\n",
      "Epoch [42/100], Loss: 0.0098, Time: 976.4214s\n",
      "Epoch [43/100], Loss: 0.0102, Time: 995.4991s\n",
      "Epoch [44/100], Loss: 0.0106, Time: 1014.5790s\n",
      "Epoch [45/100], Loss: 0.0114, Time: 1033.6656s\n",
      "Epoch [46/100], Loss: 0.0832, Time: 1052.7524s\n",
      "Epoch [47/100], Loss: 0.0085, Time: 1071.8646s\n",
      "Epoch [48/100], Loss: 0.0225, Time: 1090.9447s\n",
      "Epoch [49/100], Loss: 0.0152, Time: 1110.0363s\n",
      "Epoch [50/100], Loss: 0.0136, Time: 1129.1101s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sampling loop time step: 100%|██████████| 1000/1000 [00:43<00:00, 23.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Got 9/9 fake images.\n",
      "Epoch [51/100], Loss: 0.0070, Time: 1191.6908s\n",
      "Epoch [52/100], Loss: 0.0063, Time: 1210.7739s\n",
      "Epoch [53/100], Loss: 0.0179, Time: 1229.8639s\n",
      "Epoch [54/100], Loss: 0.0072, Time: 1248.9771s\n",
      "Epoch [55/100], Loss: 0.0622, Time: 1268.0371s\n",
      "Epoch [56/100], Loss: 0.1754, Time: 1287.1550s\n",
      "Epoch [57/100], Loss: 0.0345, Time: 1306.3165s\n",
      "Epoch [58/100], Loss: 0.0398, Time: 1325.4009s\n",
      "Epoch [59/100], Loss: 0.0315, Time: 1344.5258s\n",
      "Epoch [60/100], Loss: 0.0045, Time: 1363.6449s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sampling loop time step: 100%|██████████| 1000/1000 [00:43<00:00, 23.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Got 9/9 fake images.\n",
      "Epoch [61/100], Loss: 0.1019, Time: 1426.2492s\n",
      "Epoch [62/100], Loss: 0.0664, Time: 1445.3292s\n",
      "Epoch [63/100], Loss: 0.0114, Time: 1464.4120s\n",
      "Epoch [64/100], Loss: 0.0203, Time: 1483.5283s\n",
      "Epoch [65/100], Loss: 0.0173, Time: 1502.6239s\n",
      "Epoch [66/100], Loss: 0.0132, Time: 1521.7185s\n",
      "Epoch [67/100], Loss: 0.0120, Time: 1540.8190s\n",
      "Epoch [68/100], Loss: 0.0163, Time: 1559.9384s\n",
      "Epoch [69/100], Loss: 0.0115, Time: 1579.0400s\n",
      "Epoch [70/100], Loss: 0.0389, Time: 1598.2064s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sampling loop time step: 100%|██████████| 1000/1000 [00:43<00:00, 23.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Got 9/9 fake images.\n",
      "Epoch [71/100], Loss: 0.0421, Time: 1660.7501s\n",
      "Epoch [72/100], Loss: 0.0275, Time: 1679.8868s\n",
      "Epoch [73/100], Loss: 0.0158, Time: 1698.9933s\n",
      "Epoch [74/100], Loss: 0.0144, Time: 1718.1420s\n",
      "Epoch [75/100], Loss: 0.0112, Time: 1737.2430s\n",
      "Epoch [76/100], Loss: 0.0196, Time: 1756.3547s\n",
      "Epoch [77/100], Loss: 0.0193, Time: 1775.4470s\n",
      "Epoch [78/100], Loss: 0.0064, Time: 1794.5394s\n",
      "Epoch [79/100], Loss: 0.0218, Time: 1813.6415s\n",
      "Epoch [80/100], Loss: 0.0194, Time: 1832.7402s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sampling loop time step: 100%|██████████| 1000/1000 [00:43<00:00, 23.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Got 9/9 fake images.\n",
      "Epoch [81/100], Loss: 0.0066, Time: 1895.3923s\n",
      "Epoch [82/100], Loss: 0.0074, Time: 1914.4966s\n",
      "Epoch [83/100], Loss: 0.0309, Time: 1933.5918s\n",
      "Epoch [84/100], Loss: 0.0504, Time: 1952.6754s\n",
      "Epoch [85/100], Loss: 0.0173, Time: 1971.7595s\n",
      "Epoch [86/100], Loss: 0.0181, Time: 1990.9254s\n",
      "Epoch [87/100], Loss: 0.0334, Time: 2010.0862s\n",
      "Epoch [88/100], Loss: 0.0197, Time: 2029.2485s\n",
      "Epoch [89/100], Loss: 0.0154, Time: 2048.3640s\n",
      "Epoch [90/100], Loss: 0.0165, Time: 2067.5241s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sampling loop time step: 100%|██████████| 1000/1000 [00:43<00:00, 23.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Got 9/9 fake images.\n",
      "Epoch [91/100], Loss: 0.0140, Time: 2130.0870s\n",
      "Epoch [92/100], Loss: 0.0106, Time: 2149.1900s\n",
      "Epoch [93/100], Loss: 0.0048, Time: 2168.2835s\n",
      "Epoch [94/100], Loss: 0.0539, Time: 2187.3724s\n",
      "Epoch [95/100], Loss: 0.0221, Time: 2206.5455s\n",
      "Epoch [96/100], Loss: 0.0701, Time: 2225.6264s\n",
      "Epoch [97/100], Loss: 0.0119, Time: 2244.7693s\n",
      "Epoch [98/100], Loss: 0.0306, Time: 2263.8735s\n",
      "Epoch [99/100], Loss: 0.0061, Time: 2282.9778s\n",
      "Epoch [100/100], Loss: 0.0075, Time: 2302.0613s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sampling loop time step: 100%|██████████| 1000/1000 [00:43<00:00, 23.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Got 9/9 fake images.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sampling loop time step: 100%|██████████| 1000/1000 [07:23<00:00,  2.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Got 100/500 fake images.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sampling loop time step: 100%|██████████| 1000/1000 [07:23<00:00,  2.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Got 200/500 fake images.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sampling loop time step: 100%|██████████| 1000/1000 [07:23<00:00,  2.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Got 300/500 fake images.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sampling loop time step: 100%|██████████| 1000/1000 [07:23<00:00,  2.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Got 400/500 fake images.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sampling loop time step: 100%|██████████| 1000/1000 [07:23<00:00,  2.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Got 500/500 fake images.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from typing import List\n",
    "from abc import abstractmethod\n",
    "from torchvision import transforms, utils\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "seed = 1130\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(seed)\n",
    "\n",
    "setup_name = \"DDPM1130\"\n",
    "data_path = \"Cloud\"\n",
    "output_path = \"./outcome/{}\".format(setup_name)\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "path_to_saved_models = os.path.join(output_path, \"saved_models\")\n",
    "os.makedirs(path_to_saved_models, exist_ok=True)\n",
    "path_to_saved_images = os.path.join(output_path, \"saved_images\")\n",
    "os.makedirs(path_to_saved_images, exist_ok=True)\n",
    "\n",
    "NC = 3\n",
    "IMG_SIZE = 128\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 32  \n",
    "LR = 5e-5\n",
    "TIMESTEPS = 1000\n",
    "SAVE_FREQ = 20  \n",
    "SHOW_FREQ = 10 \n",
    "VAR_SCHEDULER = \"cosine\" \n",
    "NFAKE = 500  \n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "class CloudDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.image_files = [os.path.join(root_dir, f) for f in os.listdir(root_dir) if\n",
    "                            f.endswith('.png') or f.endswith('.jpg')]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_files[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image\n",
    "\n",
    "\n",
    "def timestep_embedding(timesteps, dim, max_period=10000):\n",
    "    half = dim // 2\n",
    "    freqs = torch.exp(\n",
    "        -math.log(max_period) * torch.arange(start=0, end=half, dtype=torch.float32) / half\n",
    "    ).to(device=timesteps.device)\n",
    "    args = timesteps[:, None].float() * freqs[None]\n",
    "    embedding = torch.cat([torch.cos(args), torch.sin(args)], dim=-1)\n",
    "    if dim % 2:\n",
    "        embedding = torch.cat([embedding, torch.zeros_like(embedding[:, :1])], dim=-1)\n",
    "    return embedding\n",
    "\n",
    "class TimestepBlock(nn.Module):\n",
    "    @abstractmethod\n",
    "    def forward(self, x, emb):\n",
    "        pass\n",
    "\n",
    "class TimestepEmbedSequential(nn.Sequential, TimestepBlock):\n",
    "    def forward(self, x, emb):\n",
    "        for layer in self:\n",
    "            if isinstance(layer, TimestepBlock):\n",
    "                x = layer(x, emb)\n",
    "            else:\n",
    "                x = layer(x)\n",
    "        return x\n",
    "\n",
    "def norm_layer(channels):\n",
    "    return nn.GroupNorm(32, channels)\n",
    "\n",
    "class ResidualBlock(TimestepBlock):\n",
    "    def __init__(self, in_channels, out_channels, time_channels, dropout=0.0):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            norm_layer(in_channels),\n",
    "            nn.SiLU(),\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
    "        )\n",
    "        self.time_emb = nn.Sequential(\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(time_channels, out_channels)\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            norm_layer(out_channels),\n",
    "            nn.SiLU(),\n",
    "            nn.Dropout(p=dropout),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n",
    "        )\n",
    "        if in_channels != out_channels:\n",
    "            self.shortcut = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "        else:\n",
    "            self.shortcut = nn.Identity()\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        h = self.conv1(x)\n",
    "        h += self.time_emb(t)[:, :, None, None]\n",
    "        h = self.conv2(h)\n",
    "        return h + self.shortcut(x)\n",
    "\n",
    "class AttentionBlock(nn.Module):\n",
    "    def __init__(self, channels, num_heads=1):\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads\n",
    "        assert channels % num_heads == 0\n",
    "        self.norm = norm_layer(channels)\n",
    "        self.qkv = nn.Conv2d(channels, channels * 3, kernel_size=1, bias=False)\n",
    "        self.proj = nn.Conv2d(channels, channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, C, H, W = x.shape\n",
    "        qkv = self.qkv(self.norm(x))\n",
    "        q, k, v = qkv.reshape(B * self.num_heads, -1, H * W).chunk(3, dim=1)\n",
    "        scale = 1. / math.sqrt(math.sqrt(C // self.num_heads))\n",
    "        attn = torch.einsum(\"bct,bcs->bts\", q * scale, k * scale)\n",
    "        attn = attn.softmax(dim=-1)\n",
    "        h = torch.einsum(\"bts,bcs->bct\", attn, v)\n",
    "        h = h.reshape(B, -1, H, W)\n",
    "        h = self.proj(h)\n",
    "        return h + x\n",
    "\n",
    "class Upsample(nn.Module):\n",
    "    def __init__(self, channels, use_conv=True):\n",
    "        super().__init__()\n",
    "        self.use_conv = use_conv\n",
    "        if use_conv:\n",
    "            self.conv = nn.Conv2d(channels, channels, kernel_size=3, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.interpolate(x, scale_factor=2, mode=\"nearest\")\n",
    "        if self.use_conv:\n",
    "            x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "class Downsample(nn.Module):\n",
    "    def __init__(self, channels, use_conv=True):\n",
    "        super().__init__()\n",
    "        self.use_conv = use_conv\n",
    "        if use_conv:\n",
    "            self.op = nn.Conv2d(channels, channels, kernel_size=3, stride=2, padding=1)\n",
    "        else:\n",
    "            self.op = nn.AvgPool2d(stride=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.op(x)\n",
    "\n",
    "\n",
    "class UNetModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int = 3,\n",
    "        model_channels: int = 128,\n",
    "        out_channels: int = 3,\n",
    "        num_res_blocks: int = 2,\n",
    "        attention_resolutions: List[int] = [16, 32],\n",
    "        dropout: float = 0.0,\n",
    "        channel_mult: List[int] = [1, 2, 4, 8],\n",
    "        conv_resample: bool = True,\n",
    "        num_heads: int = 4,\n",
    "        time_embed_dim: int = 512\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.model_channels = model_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.num_res_blocks = num_res_blocks\n",
    "        self.attention_resolutions = attention_resolutions\n",
    "        self.dropout = dropout\n",
    "        self.channel_mult = channel_mult\n",
    "        self.conv_resample = conv_resample\n",
    "        self.num_heads = num_heads\n",
    "        self.time_embed_dim = time_embed_dim\n",
    "\n",
    "        self.time_embed = nn.Sequential(\n",
    "            nn.Linear(model_channels, time_embed_dim),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(time_embed_dim, time_embed_dim),\n",
    "        )\n",
    "\n",
    "        self.input_blocks = nn.ModuleList([\n",
    "            TimestepEmbedSequential(nn.Conv2d(in_channels, model_channels, kernel_size=3, padding=1))\n",
    "        ])\n",
    "\n",
    "        current_channel = model_channels\n",
    "        input_block_chans = [current_channel]\n",
    "        downsample_layers = len(channel_mult)\n",
    "        for level, mult in enumerate(channel_mult):\n",
    "            for _ in range(num_res_blocks):\n",
    "                layers = [\n",
    "                    ResidualBlock(current_channel, mult * model_channels, time_embed_dim, dropout)\n",
    "                ]\n",
    "                current_channel = mult * model_channels\n",
    "                if level < downsample_layers and (current_channel in attention_resolutions or current_channel // 2 in attention_resolutions):\n",
    "                    layers.append(AttentionBlock(current_channel, num_heads=num_heads))\n",
    "                self.input_blocks.append(TimestepEmbedSequential(*layers))\n",
    "                input_block_chans.append(current_channel)\n",
    "            if level != downsample_layers - 1:\n",
    "                self.input_blocks.append(TimestepEmbedSequential(Downsample(current_channel, conv_resample)))\n",
    "                input_block_chans.append(current_channel)\n",
    "\n",
    "        self.middle_block = TimestepEmbedSequential(\n",
    "            ResidualBlock(current_channel, current_channel, time_embed_dim, dropout),\n",
    "            AttentionBlock(current_channel, num_heads=num_heads),\n",
    "            ResidualBlock(current_channel, current_channel, time_embed_dim, dropout)\n",
    "        )\n",
    "\n",
    "        self.output_blocks = nn.ModuleList([])\n",
    "        for level, mult in list(enumerate(channel_mult))[::-1]:\n",
    "            for i in range(num_res_blocks + 1):\n",
    "                layers = [\n",
    "                    ResidualBlock(\n",
    "                        current_channel + input_block_chans.pop(),\n",
    "                        model_channels * mult,\n",
    "                        time_embed_dim,\n",
    "                        dropout\n",
    "                    )\n",
    "                ]\n",
    "                current_channel = model_channels * mult\n",
    "                if level and i == num_res_blocks:\n",
    "                    layers.append(Upsample(current_channel, conv_resample))\n",
    "                if level < downsample_layers and (current_channel in attention_resolutions or current_channel // 2 in attention_resolutions):\n",
    "                    layers.append(AttentionBlock(current_channel, num_heads=num_heads))\n",
    "                self.output_blocks.append(TimestepEmbedSequential(*layers))\n",
    "\n",
    "        self.out = nn.Sequential(\n",
    "            norm_layer(current_channel),\n",
    "            nn.SiLU(),\n",
    "            nn.Conv2d(current_channel, out_channels, kernel_size=3, padding=1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x, timesteps):\n",
    "        hs = []\n",
    "        emb = self.time_embed(timestep_embedding(timesteps, self.model_channels))\n",
    "\n",
    "        h = x\n",
    "        for module in self.input_blocks:\n",
    "            h = module(h, emb)\n",
    "            hs.append(h)\n",
    "\n",
    "        h = self.middle_block(h, emb)\n",
    "\n",
    "        for module in self.output_blocks:\n",
    "            cat_in = torch.cat([h, hs.pop()], dim=1)\n",
    "            h = module(cat_in, emb)\n",
    "\n",
    "        return self.out(h)\n",
    "\n",
    "\n",
    "def linear_beta_schedule(timesteps):\n",
    "    scale = 1000 / timesteps\n",
    "    beta_start = scale * 0.0001\n",
    "    beta_end = scale * 0.02\n",
    "    return torch.linspace(beta_start, beta_end, timesteps, dtype=torch.float64)\n",
    "\n",
    "def cosine_beta_schedule(timesteps, s=0.008):\n",
    "    steps = timesteps + 1\n",
    "    x = torch.linspace(0, timesteps, steps, dtype=torch.float64)\n",
    "    alphas_cumprod = torch.cos(((x / timesteps) + s) / (1 + s) * math.pi * 0.5) ** 2\n",
    "    alphas_cumprod = alphas_cumprod / alphas_cumprod[0]\n",
    "    betas = 1 - (alphas_cumprod[1:] / alphas_cumprod[:-1])\n",
    "    return torch.clip(betas, 0, 0.999)\n",
    "\n",
    "\n",
    "class GaussianDiffusion:\n",
    "    def __init__(\n",
    "        self,\n",
    "        timesteps=1000,\n",
    "        beta_schedule='linear'\n",
    "    ):\n",
    "        self.timesteps = timesteps\n",
    "\n",
    "        if beta_schedule == 'linear':\n",
    "            betas = linear_beta_schedule(timesteps)\n",
    "        elif beta_schedule == 'cosine':\n",
    "            betas = cosine_beta_schedule(timesteps)\n",
    "        else:\n",
    "            raise ValueError(f'unknown beta schedule {beta_schedule}')\n",
    "        self.betas = betas\n",
    "        self.alphas = 1. - self.betas\n",
    "        self.alphas_cumprod = torch.cumprod(self.alphas, axis=0)\n",
    "        self.alphas_cumprod_prev = F.pad(self.alphas_cumprod[:-1], (1, 0), value=1.)\n",
    "        self.sqrt_alphas_cumprod = torch.sqrt(self.alphas_cumprod)\n",
    "        self.sqrt_one_minus_alphas_cumprod = torch.sqrt(1.0 - self.alphas_cumprod)\n",
    "        self.log_one_minus_alphas_cumprod = torch.log(1.0 - self.alphas_cumprod)\n",
    "        self.sqrt_recip_alphas_cumprod = torch.sqrt(1.0 / self.alphas_cumprod)\n",
    "        self.sqrt_recipm1_alphas_cumprod = torch.sqrt(1.0 / self.alphas_cumprod - 1)\n",
    "        self.posterior_variance = (\n",
    "            self.betas * (1.0 - self.alphas_cumprod_prev) / (1.0 - self.alphas_cumprod)\n",
    "        )\n",
    "        self.posterior_log_variance_clipped = torch.log(self.posterior_variance.clamp(min =1e-20))\n",
    "        self.posterior_mean_coef1 = (\n",
    "            self.betas * torch.sqrt(self.alphas_cumprod_prev) / (1.0 - self.alphas_cumprod)\n",
    "        )\n",
    "        self.posterior_mean_coef2 = (\n",
    "            (1.0 - self.alphas_cumprod_prev)\n",
    "            * torch.sqrt(self.alphas)\n",
    "            / (1.0 - self.alphas_cumprod)\n",
    "        )\n",
    "\n",
    "    def _extract(self, a, t, x_shape):\n",
    "        batch_size = t.shape[0]\n",
    "        out = a.to(t.device).gather(0, t).float()\n",
    "        out = out.reshape(batch_size, *((1,) * (len(x_shape) - 1)))\n",
    "        return out\n",
    "\n",
    "    def q_sample(self, x_start, t, noise=None):\n",
    "        if noise is None:\n",
    "            noise = torch.randn_like(x_start)\n",
    "        sqrt_alphas_cumprod_t = self._extract(self.sqrt_alphas_cumprod, t, x_start.shape)\n",
    "        sqrt_one_minus_alphas_cumprod_t = self._extract(self.sqrt_one_minus_alphas_cumprod, t, x_start.shape)\n",
    "        return sqrt_alphas_cumprod_t * x_start + sqrt_one_minus_alphas_cumprod_t * noise\n",
    "\n",
    "    def q_mean_variance(self, x_start, t):\n",
    "        mean = self._extract(self.sqrt_alphas_cumprod, t, x_start.shape) * x_start\n",
    "        variance = self._extract(1.0 - self.alphas_cumprod, t, x_start.shape)\n",
    "        log_variance = self._extract(self.log_one_minus_alphas_cumprod, t, x_start.shape)\n",
    "        return mean, variance, log_variance\n",
    "\n",
    "    def q_posterior_mean_variance(self, x_start, x_t, t):\n",
    "        posterior_mean = (\n",
    "            self._extract(self.posterior_mean_coef1, t, x_t.shape) * x_start\n",
    "            + self._extract(self.posterior_mean_coef2, t, x_t.shape) * x_t\n",
    "        )\n",
    "        posterior_variance = self._extract(self.posterior_variance, t, x_t.shape)\n",
    "        posterior_log_variance_clipped = self._extract(self.posterior_log_variance_clipped, t, x_t.shape)\n",
    "        return posterior_mean, posterior_variance, posterior_log_variance_clipped\n",
    "\n",
    "    def predict_start_from_noise(self, x_t, t, noise):\n",
    "        return (\n",
    "            self._extract(self.sqrt_recip_alphas_cumprod, t, x_t.shape) * x_t -\n",
    "            self._extract(self.sqrt_recipm1_alphas_cumprod, t, x_t.shape) * noise\n",
    "        )\n",
    "\n",
    "    def p_mean_variance(self, model, x_t, t, clip_denoised=True):\n",
    "        pred_noise = model(x_t, t)\n",
    "        x_recon = self.predict_start_from_noise(x_t, t, pred_noise)\n",
    "        if clip_denoised:\n",
    "            x_recon = torch.clamp(x_recon, min=-1., max=1.)\n",
    "        model_mean, posterior_variance, posterior_log_variance = \\\n",
    "                    self.q_posterior_mean_variance(x_recon, x_t, t)\n",
    "        return model_mean, posterior_variance, posterior_log_variance\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def p_sample(self, model, x_t, t, clip_denoised=True):\n",
    "        model_mean, _, model_log_variance = self.p_mean_variance(model, x_t, t,\n",
    "                                                    clip_denoised=clip_denoised)\n",
    "        noise = torch.randn_like(x_t)\n",
    "        nonzero_mask = ((t != 0).float().view(-1, *([1] * (len(x_t.shape) - 1))))\n",
    "        pred_img = model_mean + nonzero_mask * (0.5 * model_log_variance).exp() * noise\n",
    "        return pred_img\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def p_sample_loop(self, model, shape):\n",
    "        batch_size = shape[0]\n",
    "        device = next(model.parameters()).device\n",
    "        img = torch.randn(shape, device=device)\n",
    "        for i in tqdm(reversed(range(0, self.timesteps)), desc='sampling loop time step', total=self.timesteps):\n",
    "            img = self.p_sample(model, img, torch.full((batch_size,), i, device=device, dtype=torch.long))\n",
    "        return img.cpu()\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def sample(self, model, nfake, image_size, batch_size=100, channels=3, to_numpy=False, unnorm_to_zero2one=True):\n",
    "        if batch_size > nfake:\n",
    "            batch_size = nfake\n",
    "        assert nfake % batch_size == 0\n",
    "\n",
    "        fake_images = []\n",
    "        ngot = 0\n",
    "        while ngot < nfake:\n",
    "            batch_fake_images = self.p_sample_loop(model, shape=(batch_size, channels, image_size, image_size))\n",
    "            fake_images.append(batch_fake_images)\n",
    "            ngot += len(batch_fake_images)\n",
    "            print(\"\\r Got {}/{} fake images.\".format(ngot, nfake))\n",
    "        fake_images = torch.cat(fake_images, dim=0)\n",
    "\n",
    "        if unnorm_to_zero2one:\n",
    "            fake_images = (fake_images + 1) * 0.5\n",
    "        if to_numpy:\n",
    "            fake_images = fake_images.numpy()\n",
    "\n",
    "        return fake_images\n",
    "\n",
    "    def train_losses(self, model, x_start, t):\n",
    "        noise = torch.randn_like(x_start)\n",
    "        x_noisy = self.q_sample(x_start, t, noise=noise)\n",
    "        predicted_noise = model(x_noisy, t)\n",
    "        loss = F.mse_loss(noise, predicted_noise)\n",
    "        return loss\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "cloud_dataset = CloudDataset(root_dir=data_path, transform=transform)\n",
    "train_loader = DataLoader(cloud_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "\n",
    "model = UNetModel(\n",
    "    in_channels=NC,\n",
    "    model_channels=64,\n",
    "    out_channels=NC,\n",
    "    channel_mult=(1, 2, 4),\n",
    "    attention_resolutions=[8]\n",
    ").to(device)\n",
    "\n",
    "gaussian_diffusion = GaussianDiffusion(timesteps=TIMESTEPS, beta_schedule=VAR_SCHEDULER)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    for step, images in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        images = images.to(device)\n",
    "        t = torch.randint(0, TIMESTEPS, (images.shape[0],), device=device).long()\n",
    "        loss = gaussian_diffusion.train_losses(model, images, t)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch [{epoch+1}/{EPOCHS}], Loss: {loss.item():.4f}, Time: {time.time() - start_time:.4f}s\")\n",
    "\n",
    "    if (epoch + 1) % SAVE_FREQ == 0:\n",
    "        save_file = os.path.join(path_to_saved_models, f\"ckpt_epoch_{epoch+1}.pth\")\n",
    "        torch.save({\n",
    "            'model': model.state_dict(),\n",
    "        }, save_file)\n",
    "\n",
    "    if (epoch + 1) % SHOW_FREQ == 0:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            gen_imgs = gaussian_diffusion.sample(model, nfake=9, image_size=IMG_SIZE, batch_size=9, channels=NC, to_numpy=False, unnorm_to_zero2one=True)\n",
    "            save_file = os.path.join(path_to_saved_images, f'imgs_in_train_epoch_{epoch+1}.jpg')\n",
    "            utils.save_image(gen_imgs, save_file, nrow=3, normalize=True)  \n",
    "            \n",
    "\n",
    "test_output_path = os.path.join(output_path, \"result\")\n",
    "os.makedirs(test_output_path, exist_ok=True)\n",
    "test_images = gaussian_diffusion.sample(model, NFAKE, image_size=IMG_SIZE, batch_size=100, channels=NC, to_numpy=False, unnorm_to_zero2one=True)\n",
    "for i, img in enumerate(test_images):\n",
    "    save_file = os.path.join(test_output_path, f'gen_img_{i+1:03d}.jpg')\n",
    "    utils.save_image(img, save_file, normalize=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
